{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_FffPybYBu-j"
   },
   "source": [
    "\n",
    "# Project-2: Wrangle OpenStreetMap Data\n",
    "---\n",
    "<div style=\"text-align: justify\"> Project Submitted as part of AIRBUS Data Analyst Nanodegree. </div>\n",
    "<div style=\"text-align: right\"> by: Pankaj NATH on April 05, 2020 (Iss.1.1).</div>\n",
    "\n",
    "---\n",
    "## Table of Revisons\n",
    "Issue | Date | Reason for Revision\n",
    "--- | --- | ---\n",
    "1.0  | 04/04/2020 | First version.  \n",
    "1.1  | 05/04/2020 | Updated based on review conmments.\n",
    "\n",
    "## Table of Contents\n",
    "<ul>\n",
    "<li><a href=\"#intro\">Introduction: Map Area</a></li>\n",
    "<li><a href=\"#problem\">Problems Encountered in the Map</a></li>\n",
    "<li><a href=\"#overview\">Data Overview</a></li>\n",
    "<li><a href=\"#ideas\">Additional Ideas</a></li>\n",
    "<li><a href=\"#conclusions\">Conclusions</a></li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "V81Era83Bu-l"
   },
   "source": [
    "<a id='intro'></a>\n",
    "## Introduction: Map Area\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CuiosvJVBu-m"
   },
   "source": [
    "This report is made towards project submission for Data Wrangling of OpenStreeMap data. I selected the Whitefield locality of East Bengaluru (previously named as Bangalore), a southern city of India which is also known as India's Silicon-Valley. The reason for selecting this map location is because I am residing in this part of the city form last 7 years. During this period of time, I had changed my office and appartment few times and has explored this neighbourhoods many times.  \n",
    "The objective of this project is to download map data from [OpenStreetMap](https://www.openstreetmap.org) and apply different data wrangling techniques to audit data quality and improve data quality and parse the OSM map data into CSVs, importing CSVs to SQL tables. The improved data is then loaded into SQL database and queried to get other insights on it.  \n",
    "I have used python scripts to audit and clean OSM data and parse them into CSVs and creating database file. All these I have done using [JupyterLab](https://jupyter.org/try). This is an online platform for Jupyter Notebook. Later I imported the database file to [SQL Online](https://sqliteonline.com/) platform to execute my SQL quries. This is also another online platfor for SQLite. Usage of online platforms during this project work was really a very unique, smooth and hassele free experience for me. \n",
    "  \n",
    "Information on the map data used for the project:  \n",
    "**Location**: Whitefield, Bengaluru, India.  \n",
    "**Download link**: https://www.openstreetmap.org/export#map=12/12.9716/77.7472\n",
    "  \n",
    "This project includes below listed files:\n",
    "\n",
    "> 1. **OpenStreetMap_DataWrangling.ipynb**: This Project report as a Jupyter Notebook.\n",
    "> 2. **OpenStreetMap_DataWrangling.pdf**: This Project report in PDF format.\n",
    "> 3. **map.osm**: Map data downloaded from OpenStreetMap.\n",
    "> 4. **sample.py**: The script to make smaller extract from _map.osm_.\n",
    "> 5. **smaple.osm**: Samller extract of _map.osm_ made using _sample.py_ on which data audit is performed.\n",
    "> 6. **count_tags.py**: The script to parse _map.osm_ to count unique tags in it.\n",
    "> 7. **audit_city_postcode.py**: The script to audit city name and associated Indian Postal Codes.\n",
    "> 8. **audit_street.py**: The script to audit street names.\n",
    "> 9. **clean_city_street.py**: The script to update city and street names.\n",
    "> 10. **clean_postcode.py**: The script to update postal codes.\n",
    "> 11. **schema.py**: This is the schema for tables to be created.\n",
    "> 12. **update_convert.py**: This scripts makes use of cleaning and schema scripts to clean original OSM data and creates CSV tables.\n",
    "> 13. **create_db.py**: The script to create databse file from CSV files.\n",
    "> 14. **map.db**: This is the database file made using CSV files and _create_db.py_."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XwlG7D_KBu-r"
   },
   "source": [
    "<a id='problem'></a>\n",
    "## Problems Encountered in the Map\n",
    "\n",
    "### Data Audit  \n",
    "By parsing through **map.osm** data using **Count_tags.py** script, below result is obtained for count of unique tags in my map data:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "{'bounds': 1,\n",
    " 'member': 22462,\n",
    " 'meta': 1,\n",
    " 'nd': 627068,\n",
    " 'node': 514183,\n",
    " 'note': 1,\n",
    " 'osm': 1,\n",
    " 'relation': 464,\n",
    " 'tag': 178804,\n",
    " 'way': 111156}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the **sample.py**, a smaller extract (_sample.osm_) is created from original data (_map.osm_). This is done for quick auditing of map data by saving time of execution run on larger map data. The sample extract is created by extracting every 50th element from original map data. This sample.osm data is further used for auditing.   \n",
    "\n",
    "In India the address writing format is not as standardized as in other developed countries. The addresses in India are usually very long and does not have same format throughout the country. For the map zone of Whitefield, Bengaluru, it is true that a street name, city name and a postal code as per locality is a must. Using **audit_city_postcode.py** and **audit_street.py** two dictionaries of different city names & their postal code and street names is created.  \n",
    "  \n",
    "The postal codes in India are of 6-digits and for the map zone of Whitefield area it shall be in 560xxx format. From the audit of postal code, I identified that the old city name **_Bangalore_** is still used and not the new name **_Bengaluru_**. I propose to update the city name and harmonize the postal code.  \n",
    "  \n",
    "The harmonization of postal code and update of city and street names is achieved programatically using **clean_postcode.py** and **clean_city_street.py** scripts respectively.\n",
    "  \n",
    "### City Name Corrections    \n",
    "The city name is presnt in OSM data with tag k= 'addr:city'.\n",
    "1. 'Bangalore' -> 'Bengaluru'  \n",
    "2. 'bangalore' -> 'Bengaluru'\n",
    "3. 'bengaluru' -> 'Bengaluru'    \n",
    "  \n",
    "### Postal Code Harmonization\n",
    "The city name is presnt in OSM data with tag k= 'addr:postcode'.\n",
    "1. If postal code is empty then no action.\n",
    "2. If postal code does not begin with '560' then make them empty.\n",
    "3. If postal code is not of 6 digits then make them empty.  \n",
    "4. If postal code is of 6-digits begining with '560' then no action.\n",
    "\n",
    "### Street Name updates  \n",
    "The city name is presnt in OSM data with tag k= 'addr:street'.\n",
    "1. Updating the first letter in the name spellings to uppercase.  \n",
    "2. Delete all special characters from street names.  \n",
    "3. Updating abbreviation from 'Rd'/'Rd.' to 'Road', 'Ft'/'Ft.' to 'Feet' and other similar updates.\n",
    "  \n",
    "Once all cleaning is performed on **map.osm** data, XML data is converted to following five CSV tables using **update_convert.py** and **schema.py**:  \n",
    "> 1. **nodes.csv**\n",
    "> 2. **nodes_tags.csv**\n",
    "> 3. **ways.csv**\n",
    "> 4. **ways_nodes.csv**\n",
    "> 5. **ways_tags.csv**  \n",
    "\n",
    "Above five CSVs were then used to build **map.db** database file. This database file is then used in SQLite. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AS1atrbpBu_g"
   },
   "source": [
    "<a id='overview'></a>\n",
    "## Data Overview\n",
    "  \n",
    "This section of the reports provides some statistical overview on the files size and other informations extracted from the database with SQL querries.\n",
    "\n",
    "### File sizes  \n",
    "1. **map.osm**: 113 MB\n",
    "2. **sample.osm**: 2.29 MB \n",
    "3. **nodes.csv**: 40.9 MB\n",
    "4. **nodes_tags.csv**: 1.4 MB\n",
    "5. **ways.csv**: 6.43 MB\n",
    "6. **ways_nodes.csv**: 14.3 MB\n",
    "7. **ways_tags.csv**: 4.55 MB\n",
    "8. **map.db**: 76.9 MB  \n",
    "  \n",
    "### Number of Unique Users\n",
    "With below query, Number of unique users contributing to map data is **1157**."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "SELECT COUNT(distinct(uid))\n",
    "FROM (SELECT uid FROM nodes UNION ALL SELECT uid FROM ways)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of Nodes\n",
    "With below query, Number of nodes in map data is **514183**."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "SELECT COUNT(*) FROM nodes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of Ways\n",
    "With below query, Number of ways in map data is **111156**."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "SELECT COUNT(*) FROM ways"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Top Postal Code\n",
    "With below query, top 3 most used postal codes from map data is queried as:  \n",
    "  \n",
    "| Post Code | Count |\n",
    "|-----------|-------|\n",
    "| 560037    | 209   |\n",
    "| 560066    | 202   |\n",
    "| 560103    | 140   |"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "SELECT n.value, COUNT(*) as count\n",
    "FROM\n",
    "(SELECT * FROM ways_tags UNION ALL\n",
    "SELECT * FROM nodes_tags) n\n",
    "WHERE n.KEY='postcode'\n",
    "GROUP BY n.value\n",
    "ORDER BY count DESC\n",
    "LIMIT 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Top Amenities\n",
    "With below query, top 5 amenities from map data is queried as:  \n",
    "  \n",
    "| Amenity          | Count |\n",
    "|------------------|-------|\n",
    "| restaurant       | 648   |\n",
    "| atm              | 223   |\n",
    "| bank             | 215   |\n",
    "| place_of_worship | 213   |\n",
    "| fast_food        | 211   |"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "SELECT value, COUNT(*) as count\n",
    "FROM nodes_tags\n",
    "WHERE key='amenity'\n",
    "GROUP BY value\n",
    "ORDER BY count DESC\n",
    "LIMIT 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='ideas'></a>\n",
    "## Additional Ideas\n",
    "  \n",
    "### City and Street names in address\n",
    "I observed that many of the street name fields contain the complete address including city name and postal code. I propose additionally we can identify such entries in map data and remove city name and postal code from street name field. If not present then, city name and postal code can be added as new tags for those nodes.  \n",
    "##### Benefit(s):  \n",
    "This will bring some uniformity and standardize the address throughout the data. Not to forget, manual data reading and interpretation will improve as well.  \n",
    "##### Anticipated Problem(s):  \n",
    "The proposed solution should take care of all scenarios possible before removing user provided city names and postal codes. This solution only reorganizes and makes the user input data more readable but it doesn't gaurantees that the city name and postal code would be correct!\n",
    "  \n",
    "### Postal Code\n",
    "I assumed first 100 postal codes to be present in my map data during this project. As an additional idea, I propose to make use of Indian Postal departments complete list of postal code extract from their website which also contains city or locality name. Then make use of this extract to update postal code in our map data corresponding to its steet, locality or city name.  \n",
    "  \n",
    "Above idea is supported by the fact that below query gives three postal codes **570008, 625009 and 530103**. None of these begin with '560' as expected.  \n",
    "  \n",
    "   SELECT DISTINCT(value) FROM nodes_tags  \n",
    "   WHERE key='postcode' AND value NOT LIKE '560%'  \n",
    "  \n",
    "With a google search using keyword _pincode 570008_, I found this code belongs to Mysore (Mysuru, new name) which is a different city altogether. Similarly _625009_ belongs to Madurai city which is in a different state altogether and _530103_ is an invalid code which doesn't exist.  \n",
    "##### Benefit(s):  \n",
    "Implementation of this solution will remove all wrong post codes and also it can fulfill the post codes which are missing based on the city or locality names (if present).  \n",
    "##### Anticipated Problem(s):  \n",
    "If the user provided city or locality name is incorrect then this could lead to wrong post code assignment. Hence the solution should also be smart enough to check nearby post codes before taking any decision. Building such a smart solution may be require additional efforts but return of value may be insignificant.  \n",
    "\n",
    "### Tags\n",
    "I observed that some nodes have very few tags and others have more. This discrepancy can be further checked and if some key places are missing these tags then they can be fulfilled as well.  \n",
    "##### Benefit(s):  \n",
    "Implemention of such a solution will bring completeness in map data.  \n",
    "##### Anticipated Problem(s):  \n",
    "It could be possible that not all tags are needed for any particular location, this may then lead to too many empty tags associated to all location. It may then impact the size of map data by increasing its size without much value addition. Hence probably we should identify the node types to categorize them and then allocated  minimum tags which much be present for each particular node type. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "icsiW7S8Bu_l"
   },
   "source": [
    "<a id='conclusions'></a>\n",
    "## Conclusions\n",
    "The OpenStreetMap data for Whitefield, Bengaluru is not uniform throughout. There are above 1000 users who contributed to this map data.  \n",
    "As already discussed the problems with address format in India, manual entry of data further pollutes the data. As a part of this project, it is demonstrated that such cleaning is possible and by working on additional ideas proposed above, higher quality of data can be achieved.  \n",
    "As another measure, OpenStreetMap can put in place some control measures so that users do not intensionally pollutes the common tags like city name and postcodes."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "investigate-a-dataset-template.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
